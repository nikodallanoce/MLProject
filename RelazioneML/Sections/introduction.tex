\section{Introduction}
%L'obiettivo prefissato del progetto consisteva nel costruire un network implementando le sue funzioni principali (feed foward, back-propagation, weights update) per effettuare dei classification task sui monk test (usati come primo assemblaggio del network) e un regression task sul Cup set, in modo da prendere parte alla sfida proposta dal professore. La libreria da noi creata permette la gestione dei vari iperparametri elencati di seguito: numero di layer, numero di nodi per ciascun layer, learning rate, momentum di Nesterov, weight decay, dimensione batch (stocastico, mini-batch, batch), funzione di attivazione per gli hidden layer e per l'output layer e la funzione di loss.
The goal of the project was to build a network by implementing its main functions (feed forward, back-propagation, weights update) with the aim to solve classification tasks on the MONKS datasets and regression tasks on the CUP dataset, the former for a preliminary network setup and the latter to take part in the professor's proposed challenge. Our library allows the management of the many hyper-parameters used by network: \#layer, \#nodes for layer, learning rate, Nestorov's momentum, weight decay, batch size (ranging from a stochastic to a full-batch approach), activation functions for the hidden and output layers and the loss functions for data inference.
\vspace{3mm}

%Per raggiungere l'obiettivo postoci, abbiamo trovato, per ciascun task, il modello maggiormente adatto basandoci sui migliori iperparametri raccolti tramite una grid search con k-fold cross-validation mantenendo un bias verso le configurazioni producenti funzioni di loss pi√π smooth o con rumore non estremamente elevato.
To reach our goal we've found the best model for each task by choosing the hyperparameters trough a grid-search with k-fold cross-validation, keeping a bias towards the configurations that produced smoother plots and with less overall noise.